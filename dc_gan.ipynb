{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ISLP7e8o6ZDK",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# importing Neccessary Library and constant variable\n",
    "\n",
    "# !pip install tf_clahe\n",
    "# !pip install -U scikit-learn\n",
    "# !pip install matplotlib\n",
    "# !pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "import tensorflow_io as tfio\n",
    "\n",
    "import tf_clahe\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "from packaging import version\n",
    "import os\n",
    "from packaging import version\n",
    "from datetime import datetime\n",
    "# Import writer class from csv module\n",
    "from csv import DictWriter\n",
    "\n",
    "from sklearn.metrics import roc_curve, auc, precision_score, recall_score, f1_score\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "IMG_H = 64\n",
    "IMG_W = 64\n",
    "IMG_C = 3  ## Change this to 1 for grayscale.\n",
    "\n",
    "print(\"TensorFlow version: \", tf.__version__)\n",
    "assert version.parse(tf.__version__).release[0] >= 2, \\\n",
    "    \"This notebook requires TensorFlow 2.0 or above.\"\n",
    "\n",
    "# Weight initializers for the Generator network\n",
    "WEIGHT_INIT = tf.keras.initializers.RandomNormal(mean=0.0, stddev=0.2)\n",
    "AUTOTUNE = tf.data.AUTOTUNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(image_path):\n",
    "    img = tf.io.read_file(image_path)\n",
    "    img = tf.io.decode_jpeg(img, channels=IMG_C)\n",
    "    img = tf.image.resize_with_crop_or_pad(img, IMG_H, IMG_W)\n",
    "    img = tf.cast(img, tf.float32)\n",
    "#     rescailing image from 0,255 to -1,1\n",
    "    img = (img - 127.5) / 127.5\n",
    "    \n",
    "    return img\n",
    "\n",
    "\n",
    "\n",
    "def tf_dataset(images_path, batch_size, labels=False, class_names=None):\n",
    "  \n",
    "    dataset = tf.data.Dataset.from_tensor_slices(images_path)\n",
    "    dataset = dataset.shuffle(buffer_size=10240)\n",
    "    dataset = dataset.map(load_image, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "    \n",
    "    dataset = dataset.batch(batch_size)\n",
    "    dataset = dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6nZU71ZylN0y"
   },
   "outputs": [],
   "source": [
    "# load image dataset for trainnig without labels\n",
    "def load_image_train(filename, batch_size):\n",
    "\t# load image with the preferred size\n",
    "    \n",
    "    pixels = tf_dataset(filename, batch_size)\n",
    "    \n",
    "    return pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cVbvGULAlN0y"
   },
   "outputs": [],
   "source": [
    "def plot_roc_curve(fpr, tpr, name_model):\n",
    "    plt.plot(fpr, tpr, color='orange', label='ROC')\n",
    "    plt.plot([0, 1], [0, 1], color='darkblue', linestyle='--')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "    plt.legend()\n",
    "    plt.savefig(name_model+'_roc_curve.png')\n",
    "    plt.show()\n",
    "    plt.clf()\n",
    "    \n",
    "\n",
    "\n",
    "''' calculate the auc value for lables and scores'''\n",
    "def roc(labels, scores, name_model):\n",
    "    \"\"\"Compute ROC curve and ROC area for each class\"\"\"\n",
    "    roc_auc = dict()\n",
    "    # True/False Positive Rates.\n",
    "    fpr, tpr, threshold = roc_curve(labels, scores)\n",
    "    print(\"threshold: \", threshold)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    # get a threshod that perform very well.\n",
    "    optimal_idx = np.argmax(tpr - fpr)\n",
    "    optimal_threshold = threshold[optimal_idx]\n",
    "    # draw plot for ROC-Curve\n",
    "    plot_roc_curve(fpr, tpr, name_model)\n",
    "    \n",
    "    return roc_auc, optimal_threshold\n",
    "\n",
    "def plot_loss_with_rlabel(x_value, y_value, real_label, name_model, prefix, label_axis=[\"x_label\", \"y_label\"]):\n",
    "    # 'bo-' means blue color, round points, solid lines\n",
    "    colours = [\"blue\" if x == 1.0 else \"red\" for x in real_label]\n",
    "    plt.scatter(x_value, y_value, label='loss_value',c = colours)\n",
    "#     plt.rcParams[\"figure.figsize\"] = (50,3)\n",
    "    # Set a title of the current axes.\n",
    "    plt.title(prefix + \"_\" + name_model)\n",
    "    # show a legend on the plot\n",
    "    red_patch = mpatches.Patch(color='red', label='Normal Display')\n",
    "    blue_patch = mpatches.Patch(color='blue', label='Defect Display')\n",
    "    plt.legend(handles=[red_patch, blue_patch])\n",
    "    # Display a figure.\n",
    "    plt.ylabel(label_axis[0])\n",
    "    plt.xlabel(label_axis[1])\n",
    "    plt.savefig(name_model + \"_\" + prefix +'_rec_feat_rlabel.png')\n",
    "    plt.show()\n",
    "    plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes,\n",
    "                        normalize=False,\n",
    "                        title='Confusion matrix',\n",
    "                        cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "            horizontalalignment=\"center\",\n",
    "            color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.savefig(title+'_cm.png')\n",
    "    plt.show()\n",
    "    plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xFL24bEX65GT"
   },
   "outputs": [],
   "source": [
    "def deconv_block(inputs, num_filters, kernel_size, strides, bn=True):\n",
    "    x = tf.keras.layers.Conv2DTranspose(\n",
    "        filters=num_filters,\n",
    "        kernel_size=kernel_size,\n",
    "        kernel_initializer=WEIGHT_INIT,\n",
    "        padding=\"same\",\n",
    "        strides=strides,\n",
    "        use_bias=False\n",
    "        )(inputs)\n",
    "\n",
    "    if bn:\n",
    "        x = tf.keras.layers.BatchNormalization()(x)\n",
    "        x = tf.keras.layers.LeakyReLU(alpha=0.2)(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def conv_block(inputs, num_filters, kernel_size, padding=\"same\", strides=2, activation=True):\n",
    "    x = tf.keras.layers.Conv2D(\n",
    "        filters=num_filters,\n",
    "        kernel_size=kernel_size,\n",
    "        kernel_initializer=WEIGHT_INIT,\n",
    "        padding=padding,\n",
    "        strides=strides,\n",
    "    )(inputs)\n",
    "\n",
    "    if activation:\n",
    "        x = tf.keras.layers.LeakyReLU(alpha=0.2)(x)\n",
    "        x = tf.keras.layers.Dropout(0.3)(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create generator model based on resnet50 and unet network\n",
    "def build_generator(input_shape):\n",
    "    f = [2**i for i in range(5)][::-1]\n",
    "    filters = 32\n",
    "    output_strides = 16\n",
    "    h_output = IMG_H // output_strides\n",
    "    w_output = IMG_W // output_strides\n",
    "\n",
    "    noise = tf.keras.layers.Input(shape=(input_shape,), name=\"generator_noise_input\")\n",
    "    \n",
    "    x = tf.keras.layers.Dense(f[0] * filters * h_output * w_output, use_bias=False)(noise)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.LeakyReLU(alpha=0.2)(x)\n",
    "    x = tf.keras.layers.Reshape((h_output, w_output, 16 * filters))(x)\n",
    "\n",
    "    for i in range(1, 5):\n",
    "        x = deconv_block(x,\n",
    "            num_filters=f[i] * filters,\n",
    "            kernel_size=5,\n",
    "            strides=2,\n",
    "            bn=True\n",
    "        )\n",
    "\n",
    "    x = conv_block(x,\n",
    "        num_filters=3,  ## Change this to 1 for grayscale.\n",
    "        kernel_size=5,\n",
    "        strides=1,\n",
    "        activation=True\n",
    "    )\n",
    "    fake_output = tf.keras.layers.Activation(\"tanh\")(x)\n",
    "\n",
    "    return tf.keras.models.Model(noise, fake_output, name=\"generator\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create discriminator model\n",
    "def build_discriminator():\n",
    "    f = [2**i for i in range(4)]\n",
    "    image_input = tf.keras.layers.Input(shape=(IMG_H, IMG_W, IMG_C))\n",
    "    x = image_input\n",
    "    filters = 64\n",
    "    output_strides = 16\n",
    "    h_output = IMG_H // output_strides\n",
    "    w_output = IMG_W // output_strides\n",
    "\n",
    "    for i in range(0, 4):\n",
    "        x = conv_block(x, num_filters=f[i] * filters, kernel_size=5, strides=2)\n",
    "\n",
    "    x = tf.keras.layers.Flatten()(x)\n",
    "    x = tf.keras.layers.Dense(1, activation='tanh')(x)\n",
    "\n",
    "    return tf.keras.models.Model(image_input, x, name=\"discriminator\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Bm_XokrmFnlN"
   },
   "outputs": [],
   "source": [
    "def save_plot(examples, name_model, n):\n",
    "    examples = (examples + 1) / 2.0\n",
    "    for i in range(n * n):\n",
    "        plt.subplot(n, n, i+1)\n",
    "        plt.axis(\"off\")\n",
    "        plt.imshow(examples[i])  ## pyplot.imshow(np.squeeze(examples[i], axis=-1))\n",
    "    filename = f\"samples/generated_plot-{name_model}.png\"\n",
    "    plt.savefig(filename)\n",
    "    plt.close()\n",
    "    \n",
    "\n",
    "class DCGAN(tf.keras.models.Model):\n",
    "    def __init__(self, generator, discriminator, latent_dim):\n",
    "        super(DCGAN, self).__init__()\n",
    "        self.generator = generator\n",
    "        self.discriminator = discriminator\n",
    "        self.latent_dim = latent_dim\n",
    "       \n",
    "        # Regularization Rate for each loss function\n",
    "        self.d_optimizer = tf.keras.optimizers.Adam(learning_rate=2e-6, beta_1=0.5, beta_2=0.999)\n",
    "        self.g_optimizer = tf.keras.optimizers.Adam(learning_rate=2e-6, beta_1=0.5, beta_2=0.999)\n",
    "    \n",
    "    \n",
    "    def compile(self, g_optimizer, d_optimizer, filepath, loss_fn, resume=False):\n",
    "        super(DCGAN, self).compile()\n",
    "        self.g_optimizer = g_optimizer\n",
    "        self.d_optimizer = d_optimizer\n",
    "        self.loss_fn = loss_fn\n",
    "            \n",
    "# Notice the use of `tf.function`\n",
    "# This annotation causes the function to be \"compiled\".\n",
    "    @tf.function\n",
    "    def train_step(self, real_images):\n",
    "        batch_size = tf.shape(real_images)[0]\n",
    "\n",
    "        for _ in range(2):\n",
    "            ## Train the discriminator\n",
    "            random_latent_vectors = tf.random.normal(shape=(batch_size, self.latent_dim))\n",
    "            generated_images = self.generator(random_latent_vectors)\n",
    "            generated_labels = tf.zeros((batch_size, 1))\n",
    "\n",
    "            with tf.GradientTape() as ftape:\n",
    "                predictions = self.discriminator(generated_images)\n",
    "                d1_loss = self.loss_fn(generated_labels, predictions)\n",
    "            grads = ftape.gradient(d1_loss, self.discriminator.trainable_weights)\n",
    "            self.d_optimizer.apply_gradients(zip(grads, self.discriminator.trainable_weights))\n",
    "\n",
    "            ## Train the discriminator\n",
    "            labels = tf.ones((batch_size, 1))\n",
    "\n",
    "            with tf.GradientTape() as rtape:\n",
    "                predictions = self.discriminator(real_images)\n",
    "                d2_loss = self.loss_fn(labels, predictions)\n",
    "            grads = rtape.gradient(d2_loss, self.discriminator.trainable_weights)\n",
    "            self.d_optimizer.apply_gradients(zip(grads, self.discriminator.trainable_weights))\n",
    "\n",
    "        ## Train the generator\n",
    "        random_latent_vectors = tf.random.normal(shape=(batch_size, self.latent_dim))\n",
    "        misleading_labels = tf.ones((batch_size, 1))\n",
    "\n",
    "        with tf.GradientTape() as gtape:\n",
    "            predictions = self.discriminator(self.generator(random_latent_vectors))\n",
    "            g_loss = self.loss_fn(misleading_labels, predictions)\n",
    "        grads = gtape.gradient(g_loss, self.generator.trainable_weights)\n",
    "        self.g_optimizer.apply_gradients(zip(grads, self.generator.trainable_weights))\n",
    "\n",
    "        return {\n",
    "            \"d1_loss\": d1_loss, \n",
    "            \"d2_loss\": d2_loss, \n",
    "            \"gen_loss\": g_loss\n",
    "        }\n",
    "\n",
    "    def saved_model(self, gmodelpath, dmodelpath):\n",
    "        self.generator.save(gmodelpath)\n",
    "        self.discriminator.save(dmodelpath)\n",
    "\n",
    "    def loaded_model(self, g_filepath, d_filepath):\n",
    "        self.generator.load_weights(g_filepath)\n",
    "        self.discriminator.load_weights(d_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomSaver(tf.keras.callbacks.Callback):\n",
    "    def __init__(self,\n",
    "                 g_model_path,\n",
    "                 d_model_path,\n",
    "                 logs_file,\n",
    "                 name_model\n",
    "                ):\n",
    "        super(CustomSaver, self).__init__()\n",
    "        self.g_model_path = g_model_path\n",
    "        self.d_model_path = d_model_path\n",
    "        self.logs_file = logs_file\n",
    "        self.name_model = name_model\n",
    "        self.epochs_list = []\n",
    "        self.gen_loss_list = []\n",
    "        self.disc_1_loss_list = []\n",
    "        self.disc_2_loss_list = []\n",
    "        \n",
    "    \n",
    "    def on_train_begin(self, logs=None):\n",
    "        if not hasattr(self, 'epoch'):\n",
    "            self.epoch = []\n",
    "            self.history = {}\n",
    "            \n",
    "    def on_train_end(self, logs=None):\n",
    "        self.model.saved_model(self.g_model_path, self.d_model_path)\n",
    "        \n",
    "        self.plot_epoch_result(self.epochs_list, self.gen_loss_list, \"Generator_Loss\", self.name_model, \"g\")\n",
    "        self.plot_epoch_result(self.epochs_list, self.disc_1_loss_list, \"Discriminator_Loss_1\", self.name_model, \"r\")\n",
    "        self.plot_epoch_result(self.epochs_list, self.disc_2_loss_list, \"Discriminator_Loss_2\", self.name_model, \"r\")\n",
    "    \n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        logs = logs or {}\n",
    "        self.epoch.append(epoch)\n",
    "        for k, v in logs.items():\n",
    "#             print(k, v)\n",
    "            self.history.setdefault(k, []).append(v)\n",
    "        \n",
    "        self.epochs_list.append(epoch)\n",
    "        self.gen_loss_list.append(logs[\"gen_loss\"])\n",
    "        self.disc_1_loss_list.append(logs[\"d1_loss\"])\n",
    "        self.disc_2_loss_list.append(logs[\"d2_loss\"])\n",
    "        \n",
    "        \n",
    "        if (epoch + 1) % 15 == 0 or (epoch + 1) <= 15:\n",
    "            self.model.saved_model(self.g_model_path, self.d_model_path)\n",
    "            print('saved for epoch',epoch + 1)\n",
    "            \n",
    "    def plot_epoch_result(self, epochs, loss, name, model_name, colour):\n",
    "        plt.plot(epochs, loss, colour, label=name)\n",
    "    #     plt.plot(epochs, disc_loss, 'b', label='Discriminator loss')\n",
    "        plt.title(name)\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.legend()\n",
    "        plt.savefig(model_name+ '_'+name+'_epoch_result.png')\n",
    "        plt.show()\n",
    "        plt.clf()\n",
    "\n",
    "        \n",
    "def scheduler(epoch, lr):\n",
    "    if epoch < 1500:\n",
    "        return lr\n",
    "    else:\n",
    "        return lr * tf.math.exp(-0.1)\n",
    "\n",
    "def set_callbacks(name_model, logs_path, logs_file, path_gmodal, path_dmodal, steps):\n",
    "    # create and use callback:\n",
    "    \n",
    "    saver_callback = CustomSaver(\n",
    "        path_gmodal,\n",
    "        path_dmodal,\n",
    "        logs_file,\n",
    "        name_model\n",
    "    )\n",
    "    \n",
    "    lr_callback = tf.keras.callbacks.LearningRateScheduler(scheduler)\n",
    "    \n",
    "    reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='disc_loss', factor=0.2,\n",
    "                              patience=7, min_lr=0.000001)\n",
    "    \n",
    "    tensorboard_callback = tf.keras.callbacks.TensorBoard(\n",
    "        log_dir=logs_path + name_model + \"/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\"), \n",
    "        histogram_freq=1\n",
    "    )\n",
    "    \n",
    "\n",
    "    callbacks = [\n",
    "        saver_callback,\n",
    "#         checkpoints_callback,\n",
    "        tensorboard_callback,\n",
    "#         lr_callback,\n",
    "        reduce_lr,\n",
    "    ]\n",
    "    return callbacks\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_trainning(model, train_dataset,num_epochs, path_gmodal, path_dmodal, logs_path, logs_file, name_model, steps, resume=False):\n",
    "\n",
    "    \n",
    "    \n",
    "    callbacks = set_callbacks(name_model, logs_path, logs_file, path_gmodal, path_dmodal, steps)\n",
    "            \n",
    "    model.fit(train_dataset, epochs=num_epochs, callbacks=callbacks)\n",
    "    \n",
    "def testing(model, g_filepath, latent_dim , name_model, n_samples=25):\n",
    "    noise = np.random.normal(size=(n_samples, latent_dim))\n",
    "\n",
    "    # g_model = model.load(g_filepath)\n",
    "    g_model = tf.keras.models.load_model(g_filepath)\n",
    "\n",
    "    examples = g_model.predict(noise)\n",
    "    save_plot(examples, name_model, int(np.sqrt(n_samples)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1KoSI9-4-tVt"
   },
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    '''\n",
    "    In Default:\n",
    "    Clahe: OFF\n",
    "    BCET: OFF\n",
    "    Resize: crop or padding (decided by tensorflow)\n",
    "    Datasets: For trainning dataset, it'll have additional datasets (flip-up-down and flip-right-left)\n",
    "    '''\n",
    "    \n",
    "    # run the function here\n",
    "    \"\"\" Set Hyperparameters \"\"\"\n",
    "    \n",
    "    batch_size = 128\n",
    "    num_epochs = 5\n",
    "    latent_dim = 128\n",
    "    name_model= str(IMG_H)+\"_dc_gan_\"+str(num_epochs)\n",
    "    \n",
    "    resume_trainning = False\n",
    "    lr = 1e-5\n",
    "    \n",
    "    print(\"start: \", name_model)\n",
    "    \n",
    "    # set dir of files\n",
    "    train_images_path = \"data_test/*.jpg\"\n",
    "    saved_model_path = \"saved_model/\"\n",
    "    \n",
    "    logs_path = \"logs/\"\n",
    "    \n",
    "    logs_file = logs_path + \"logs_\" + name_model + \".csv\"\n",
    "    \n",
    "    path_gmodal = saved_model_path + name_model + \"_g_model\" + \".h5\"\n",
    "    path_dmodal = saved_model_path +  name_model + \"_d_model\" + \".h5\"\n",
    "    \n",
    "    \"\"\"\n",
    "    Create a MirroredStrategy object. \n",
    "    This will handle distribution and provide a context manager (MirroredStrategy.scope) \n",
    "    to build your model inside.\n",
    "    \"\"\"\n",
    "    \n",
    "    strategy = tf.distribute.MirroredStrategy()\n",
    "    \n",
    "    print('Number of devices: {}'.format(strategy.num_replicas_in_sync))\n",
    "\n",
    "    input_shape = (IMG_H, IMG_W, IMG_C)\n",
    "    # print(input_shape)\n",
    "    \n",
    "    ## init models ##\n",
    "    \n",
    "    d_model = build_discriminator()\n",
    "    g_model = build_generator(latent_dim)\n",
    "\n",
    "    \n",
    "#     d_model.summary()\n",
    "#     g_model.summary()\n",
    "    \n",
    "    resunetgan = DCGAN(g_model, d_model, latent_dim)\n",
    "    \n",
    "    bce_loss_fn = tf.keras.losses.BinaryCrossentropy()\n",
    "    g_optimizer = tf.keras.optimizers.Adam(learning_rate=lr, beta_1=0.5, beta_2=0.999)\n",
    "    d_optimizer = tf.keras.optimizers.Adam(learning_rate=lr, beta_1=0.5, beta_2=0.999)\n",
    "    \n",
    "    resunetgan.compile(g_optimizer, d_optimizer, logs_file, bce_loss_fn, resume_trainning)\n",
    "    \n",
    "    \"\"\" run trainning process \"\"\"\n",
    "    train_images = glob(train_images_path)\n",
    "    train_images_dataset = load_image_train(train_images, batch_size)\n",
    "    train_images_dataset = train_images_dataset.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "    size_of_dataset = len(list(train_images_dataset)) * batch_size\n",
    "    \n",
    "    steps = int(size_of_dataset/batch_size)\n",
    "    run_trainning(resunetgan, train_images_dataset, num_epochs, path_gmodal, path_dmodal, logs_path, logs_file, name_model, steps,resume=resume_trainning)\n",
    "    \n",
    "    testing(g_model, path_gmodal, latent_dim, name_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "mura_detector.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
